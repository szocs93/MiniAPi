{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniAPI_colab_Ver2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szocs93/MiniAPi/blob/main/MiniAPI_colab_Juvel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDlIeP32XVZn"
      },
      "source": [
        "# **Get information about the machine**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzXIR5ydXeqG"
      },
      "source": [
        "# Disk information\n",
        "!df -h\n",
        "# CPU information\n",
        "!lscpu | grep \"MHz\"\n",
        "# If using a GPU\n",
        "!nvidia-smi -L\n",
        "!nvcc --version\n",
        "# Memory information\n",
        "!cat /proc/meminfo | grep 'MemAvailable'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in9dLN96X8EV"
      },
      "source": [
        "# **Import dependencies and CaImAn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "2IE4-nYWYBoH"
      },
      "source": [
        "from datetime import datetime\n",
        "import scipy.io as sio\n",
        "import h5py\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import time\n",
        "import logging\n",
        "!pip install holoviews\n",
        "import holoviews as hv\n",
        "import zipfile\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.style.use('default')\n",
        "import numpy as np\n",
        "from moviepy.editor import *\n",
        "import smtplib\n",
        "!pip install scikit-image\n",
        "!pip install pynwb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfVr7CsTtoDj"
      },
      "source": [
        "# Install CaImAn\n",
        "#!git clone https://github.com/flatironinstitute/CaImAn.git\n",
        "!git clone https://github.com/etterguillaume/CaImAn.git\n",
        "%cd '/content/CaImAn/'\n",
        "!pip install -e .\n",
        "\n",
        "!pip install tifffile\n",
        "!pip install ipyparallel\n",
        "!pip install peakutils\n",
        "\n",
        "%cd '/content/CaImAn/'\n",
        "!python caimanmanager.py install --inplace\n",
        "\n",
        "!export MKL_NUM_THREADS=1\n",
        "!export OPENBLAS_NUM_THREADS=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73rz617KtpYB"
      },
      "source": [
        "# This is for GPU accelaration\n",
        "!pip install pycuda\n",
        "!pip install scikit-cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-b8qP6wtrAR"
      },
      "source": [
        "\n",
        "import caiman as cm\n",
        "from caiman.source_extraction import cnmf\n",
        "from caiman.utils.visualization import inspect_correlation_pnr\n",
        "from caiman.motion_correction import MotionCorrect\n",
        "from caiman.source_extraction.cnmf import params as params\n",
        "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
        "import peakutils\n",
        "import bokeh.plotting as bpl\n",
        "try:\n",
        "       from bokeh.io import vform, hplot\n",
        "except:\n",
        "       # newer version of bokeh does not use vform & hplot, instead uses column & row\n",
        "       from bokeh.layouts import column as vform\n",
        "       from bokeh.layouts import row as hplot\n",
        "from bokeh.models import CustomJS, ColumnDataSource, Slider\n",
        "from bokeh.io import export_png\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e2y4pXotsNx"
      },
      "source": [
        "bpl.output_notebook()\n",
        "hv.notebook_extension('bokeh')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNRuptnhZjJP"
      },
      "source": [
        "# **Working directory specification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7K8Z1fzFhMy"
      },
      "source": [
        "%cd '/content/drive/MyDrive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esoGbiOPcqF1"
      },
      "source": [
        "%cd '/content/drive/MyDrive/msVideos/'\n",
        "%ls\n",
        "print('Please select the working directory: ')\n",
        "dnam = input()\n",
        "mv = %pwd\n",
        "p = mv + '/' + dnam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ6dy38eg3Vp"
      },
      "source": [
        "ido = datetime.today()\n",
        "ev = str(ido.year)\n",
        "honap = str(ido.month)\n",
        "nap = str(ido.day)\n",
        "experimentName = ev + '_' + honap + '_' + nap\n",
        "print('The name of experiment is: ' + experimentName)\n",
        "\n",
        "\n",
        "path_to_analyze = p\n",
        "analyze_behavior = False\n",
        "spatial_downsampling = 3 # Drastically speeds up processing. 2-3 recommended\n",
        "isnonrigid = False\n",
        "\n",
        "path_to_results = p + '/' + experimentName\n",
        "try:\n",
        "    os.mkdir(path_to_results) # Where to save the data\n",
        "    print(\"Result directory \" , path_to_results , \" Created\")\n",
        "except FileExistsError:\n",
        "    print(\"Directory: \" , path_to_results , \" already existed\" )\n",
        "\n",
        "    \n",
        "\n",
        "print('Parameters saved. Ready to start analyzing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_CtzSRhr9y8"
      },
      "source": [
        "path = path_to_analyze\n",
        "os.chdir(path)\n",
        "map = os.listdir(path)\n",
        "msFileList = []\n",
        "filesList = []\n",
        "for file in map:\n",
        "  filesList.append(file)\n",
        "\n",
        "for i in filesList[:]:\n",
        "  if i.startswith('ms') and i.endswith('.avi'):\n",
        "    msFileList.append(i)\n",
        "    \n",
        "\n",
        "\n",
        "msFileList = sorted(msFileList, key=lambda x: int(re.sub('[msCam.avi]','', x)))\n",
        "print('In this folder the number of msCam videos is: ')\n",
        "print(len(map))\n",
        "print(msFileList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV4lo4VEsMr5"
      },
      "source": [
        "# **Enable logging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t0JolsxsQAz"
      },
      "source": [
        "logging.basicConfig(format=\n",
        "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
        "                    # filename=\"/tmp/caiman.log\",\n",
        "                    level=logging.WARNING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez5UJtXKsWga"
      },
      "source": [
        "# **Enable parallel processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4aWtnwHsZXa"
      },
      "source": [
        "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
        "if 'dview' in locals():\n",
        "    cm.stop_server(dview=dview)\n",
        "c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "    backend='local', n_processes=None, single_thread=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HGRLznwsf17"
      },
      "source": [
        "now = datetime.now()\n",
        "analysis_time = now.strftime(\"%Y-%m-%d %H:%M\") # This is to register when the analysis was performed\n",
        "print('Analysis started on ' + analysis_time)\n",
        "\n",
        "\n",
        "analysis_start = time.time() # This is to register the time spent analyzing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMDOPzCedT-T"
      },
      "source": [
        "# Downsampling videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67LqFLD1dYiq"
      },
      "source": [
        "for video in msFileList:\n",
        "  clip = VideoFileClip(video)\n",
        "  resized_clip = clip.resize(1/spatial_downsampling)\n",
        "  os.remove(video)\n",
        "  resized_clip.write_videofile(video,codec='rawvideo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5oQtm4ad0l5"
      },
      "source": [
        "# Make sure the video has been resized\n",
        "clip = VideoFileClip(msFileList[0])\n",
        "clip.save_frame(path_to_results + '/' + 'downsampled_frame.png')\n",
        "\n",
        "img=mpl.image.imread(path_to_results + '/' + 'downsampled_frame.png')\n",
        "imgplot = plt.imshow(img); plt.title('Downsampled size')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPusspPrd28K"
      },
      "source": [
        "fnames = msFileList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8g9L_ZNsjfi"
      },
      "source": [
        "# **Motion correction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LkjUFS0smUa"
      },
      "source": [
        "## ***Motion correction parameter setup***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sGqrCBdtKqS"
      },
      "source": [
        "# dataset dependent parameters\n",
        "frate = 20                       # movie frame rate\n",
        "decay_time = 0.4                 # length of a typical transient in seconds\n",
        "dirExperimentName = path_to_analyze\n",
        "\n",
        "\n",
        "# motion correction parameters\n",
        "motion_correct = True    # flag for performing motion correction\n",
        "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
        "gSig_filt = (3, 3)     # size of high pass spatial filtering, used in 1p data\n",
        "max_shifts = (5, 5)      # maximum allowed rigid shift\n",
        "strides = (48, 48)       # start a new patch for pw-rigid motion correction every x pixels\n",
        "overlaps = (24, 24)      # overlap between pathes (size of patch strides+overlaps)\n",
        "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts\n",
        "border_nan = 'copy'      # replicate values along the boundaries\n",
        "use_cuda = True\n",
        "memory_fact = 1\n",
        "\n",
        "mc_dict = {\n",
        "    'fnames': fnames,\n",
        "    'fr': frate,\n",
        "    'decay_time': decay_time,\n",
        "    'pw_rigid': pw_rigid,\n",
        "    'max_shifts': max_shifts,\n",
        "    'gSig_filt': gSig_filt,\n",
        "    'strides': strides,\n",
        "    'overlaps': overlaps,\n",
        "    'max_deviation_rigid': max_deviation_rigid,\n",
        "    'border_nan': border_nan\n",
        "}\n",
        "\n",
        "opts = params.CNMFParams(params_dict=mc_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXR1gMQptQ2w"
      },
      "source": [
        "## ***Perform motion correction***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTvzYtaMtX7g"
      },
      "source": [
        "start = time.time()\n",
        "if motion_correct:\n",
        "    # do motion correction rigid\n",
        "    mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))\n",
        "    mc.motion_correct(save_movie=True)\n",
        "    fname_mc = mc.fname_tot_els if pw_rigid else mc.fname_tot_rig\n",
        "    \n",
        "end = time.time()\n",
        "print(end-start)\n",
        "print('Motion correction has been done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KW9PFEztx_X"
      },
      "source": [
        "## Memory map the files, load memory mappable files and restart cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmzBEssHt8Rc"
      },
      "source": [
        "if motion_correct:\n",
        "    if pw_rigid:\n",
        "        bord_px = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
        "                                     np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
        "    else:\n",
        "        bord_px = np.ceil(np.max(np.abs(mc.shifts_rig))).astype(np.int)\n",
        "\n",
        "    bord_px = 0 if border_nan is 'copy' else bord_px\n",
        "    fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C',\n",
        "                               border_to_0=bord_px)\n",
        "    \n",
        "else:  # if no motion correction just memory map the file\n",
        "    fname_new = cm.save_memmap(fnames, base_name='memmap_',\n",
        "                               order='C', border_to_0=0, dview=dview)\n",
        "    \n",
        "print('Motion corrected video has been mapped to memory!')\n",
        "\n",
        "# load memory mappable file\n",
        "Yr, dims, T = cm.load_memmap(fname_new)\n",
        "images = Yr.T.reshape((T,) + dims, order='F')\n",
        "\n",
        "#%% restart cluster to clean up memory\n",
        "cm.stop_server(dview=dview)\n",
        "c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "    backend='local', n_processes=None, single_thread=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvOWBXOGuc3e"
      },
      "source": [
        "# Perform a projection of correlated pixels (and associated signal-to-noise ratio) in motion corrected video\n",
        "This is important to assess the amounts of local correlations and peak-to-noise ratio as well as seed/initialize CNMFe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f4HHeQuuxlr"
      },
      "source": [
        "# compute some summary images (correlation and peak to noise)\n",
        "cn_filter, pnr = cm.summary_images.correlation_pnr(images[::5], gSig=3, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
        "\n",
        "#Plot the results of the correlation/PNR projection\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(2, 2, 1); plt.imshow(cn_filter); plt.colorbar(); plt.title('Correlation projection')\n",
        "plt.subplot(2, 2, 2); plt.imshow(pnr); plt.colorbar(); plt.title('PNR')\n",
        "\n",
        "print('In the CNMFe parameters please give the minimum number of CNR and PNR!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMlYXjkgvLfm"
      },
      "source": [
        "# CNMFe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw6w3PM-vP4k"
      },
      "source": [
        "## *CNMFe parameter setup*\n",
        "\n",
        "Here are just a few parameters which are key for the pipeline. For further settings please see CaImAn documentation!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahCBQhDBkrrD"
      },
      "source": [
        "mcr = input('The min correlation projection: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeNr9ss3k4lz"
      },
      "source": [
        "mpr = input('The min peak to noise ratio: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8REqlmjT-iG"
      },
      "source": [
        "#Based on the figures above, please add the mininum peak from correlation projection image and from PNR image\n",
        "\n",
        "min_corr = .3       # min peak value from correlation image\n",
        "min_pnr = 30        # min peak to noise ration from PNR image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTXPnZ9jvYXp"
      },
      "source": [
        "# parameters for source extraction and deconvolution\n",
        "p = 1               # order of the autoregressive system\n",
        "K = None            # upper bound on number of components per patch, in general None\n",
        "gSig = (3, 3)       # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
        "gSiz = (13, 13)     # average diameter of a neuron, in general 4*gSig+1\n",
        "Ain = None          # possibility to seed with predetermined binary masks\n",
        "merge_thr = .55      # merging threshold, max correlation allowed\n",
        "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
        "stride_cnmf = 20    # amount of overlap between the patches in pixels\n",
        "#                     (keep it at least large as gSiz, i.e 4 times the neuron size gSig)\n",
        "tsub = 2            # downsampling factor in time for initialization,\n",
        "#                     increase if you have memory problems\n",
        "ssub = 1            # downsampling factor in space for initialization,\n",
        "#                     increase if you have memory problems\n",
        "#                     you can pass them here as boolean vectors\n",
        "low_rank_background = None  # None leaves background of each patch intact,\n",
        "#                     True performs global low-rank approximation if gnb>0\n",
        "gnb = 1             # number of background components (rank) if positive,\n",
        "#                     else exact ring model with following settings\n",
        "#                         gnb= 0: Return background as b and W\n",
        "#                         gnb=-1: Return full rank background B\n",
        "#                         gnb<-1: Don't return background\n",
        "nb_patch = 0        # number of background components (rank) per patch if gnb>0,\n",
        "#                     else it is set automatically\n",
        "ssub_B = 2          # additional downsampling factor in space for background\n",
        "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor\n",
        "memory_fact = 1\n",
        "\n",
        "\n",
        "opts.change_params(params_dict={'method_init': 'corr_pnr',  # use this for 1 photon\n",
        "                                'K': K,\n",
        "                                'gSig': gSig,\n",
        "                                'gSiz': gSiz,\n",
        "                                'merge_thr': merge_thr,\n",
        "                                'p': p,\n",
        "                                'tsub': tsub,\n",
        "                                'ssub': ssub,\n",
        "                                'rf': rf,\n",
        "                                'stride': stride_cnmf,\n",
        "                                'only_init': True,    # set it to True to run CNMF-E\n",
        "                                'nb': gnb,\n",
        "                                'nb_patch': nb_patch,\n",
        "                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
        "                                'low_rank_background': low_rank_background,\n",
        "                                'update_background_components': True,  # sometimes setting to False improve the results\n",
        "                                'min_corr': min_corr,\n",
        "                                'min_pnr': min_pnr,\n",
        "                                'normalize_init': False,               # just leave as is\n",
        "                                'center_psf': True,                    # leave as is for 1 photon\n",
        "                                'ssub_B': ssub_B,\n",
        "                                'ring_size_factor': ring_size_factor,\n",
        "                                'del_duplicates': True,                # whether to remove duplicates from initialization\n",
        "                                'border_pix': bord_px})                # number of pixels to not consider in the borders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpaKg05svyCI"
      },
      "source": [
        "## *Perform CNMFe*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO6ujEuYv2vD"
      },
      "source": [
        "start = time.time()\n",
        "cnm = cnmf.CNMF(n_processes=n_processes, dview=dview, Ain=Ain, params=opts)\n",
        "cnm.fit(images)\n",
        "end = time.time()\n",
        "print('CNMFe done in: ')\n",
        "print(end-start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh09noAqz_S1"
      },
      "source": [
        "#%% COMPONENT EVALUATION\n",
        "# the components are evaluated in three ways:\n",
        "#   a) the shape of each component must be correlated with the data\n",
        "#   b) a minimum peak SNR is required over the length of a transient\n",
        "#   c) each shape passes a CNN based classifier\n",
        "\n",
        "min_SNR = 3            # adaptive way to set threshold on the transient size\n",
        "r_values_min = 0.85    # threshold on space consistency (if you lower more components\n",
        "#                        will be accepted, potentially with worst quality)\n",
        "cnm.params.set('quality', {'min_SNR': min_SNR,\n",
        "                           'rval_thr': r_values_min,\n",
        "                           'use_cnn': False})\n",
        "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
        "\n",
        "print(' ***** ')\n",
        "print('Number of total components: ', len(cnm.estimates.C))\n",
        "print('Number of accepted components: ', len(cnm.estimates.idx_components))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci4nIAIb0Fnm"
      },
      "source": [
        "# Plot results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay79wDgA0Ie0"
      },
      "source": [
        "## *Plot neuron contours*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRcaJliV0LJa"
      },
      "source": [
        "#%% plot contour plots of accepted and rejected components\n",
        "cnm.estimates.plot_contours(img=cn_filter, idx=cnm.estimates.idx_components)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6_ufkxk0Y2b"
      },
      "source": [
        "## *Plot traces and every other results*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yC_fLZJ0dDj"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "#How many neurons to plot\n",
        "neuronsToPlot = len(cnm.estimates.idx_components)\n",
        "\n",
        "DeconvTraces = cnm.estimates.S\n",
        "RawTraces = cnm.estimates.C\n",
        "SFP = cnm.estimates.A\n",
        "SFP_dims = list(dims)\n",
        "SFP_dims.append(SFP.shape[1]) \n",
        "print('Spatial foootprints dimensions (height x width x neurons): ' + str(SFP_dims))\n",
        "\n",
        "numNeurons = SFP_dims[2]\n",
        "\n",
        "SFP = np.reshape(SFP.toarray(), SFP_dims, order='F')\n",
        "\n",
        "maxRawTraces = np.amax(RawTraces)\n",
        "\n",
        "plt.figure(figsize=(30,15))\n",
        "plt.subplot(341);\n",
        "plt.subplot(345); plt.plot(mc.shifts_rig); plt.title('Motion corrected shifts')\n",
        "plt.subplot(3,4,9);\n",
        "plt.subplot(3,4,2); plt.imshow(cn_filter); plt.colorbar(); plt.title('Correlation projection')\n",
        "plt.subplot(3,4,6); plt.imshow(pnr); plt.colorbar(); plt.title('PNR')\n",
        "plt.subplot(3,4,10); plt.imshow(np.amax(SFP,axis=2)); plt.colorbar(); plt.title('Spatial footprints')\n",
        "\n",
        "plt.subplot(2,2,2); plt.figure; plt.title('Raw traces')\n",
        "plot_gain = 10 # To change the value gain of traces\n",
        "if numNeurons >= neuronsToPlot:\n",
        "  for i in range(neuronsToPlot):\n",
        "    if i == 0:\n",
        "      plt.plot(RawTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = RawTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "else:\n",
        "  for i in range(numNeurons):\n",
        "    if i == 0:\n",
        "      plt.plot(RawTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = RawTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "\n",
        "plt.subplot(2,2,4); plt.figure; plt.title('Deconvolved traces')\n",
        "plot_gain = 20 # To change the value gain of traces\n",
        "if numNeurons >= neuronsToPlot:\n",
        "  for i in range(neuronsToPlot):\n",
        "    if i == 0:\n",
        "      plt.plot(DeconvTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = DeconvTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "else:\n",
        "  for i in range(numNeurons):\n",
        "    if i == 0:\n",
        "      plt.plot(DeconvTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = DeconvTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')      \n",
        "\n",
        "# Save summary figure\n",
        "plt.savefig(path_to_results + '/' + 'summary_figure.svg', edgecolor='w', format='svg', transparent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIWQWGB7Dq-9"
      },
      "source": [
        "save_hdf5 = False\n",
        "if save_hdf5:\n",
        "    cnm.save(path_to_results + '/' + 'analysis_results.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1prfbYUUXii"
      },
      "source": [
        "# Delete unwanted neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVLgYPh-UbQu"
      },
      "source": [
        "n = len(cnm.estimates.C)\n",
        "j = [0] * n\n",
        "for k in range(len(cnm.estimates.C)):\n",
        "    plt.figure()\n",
        "    plt.plot(RawTraces[k,:])\n",
        "    plt.pause(0.2)\n",
        "    j[k] = input(\"Is it a good trace or not? If yes press 1, if not press 0!:\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4AxROkLUe7R"
      },
      "source": [
        "print(j)\n",
        "res = [idx for idx, val in enumerate(j) if val != '0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkX8sPaneBpM"
      },
      "source": [
        "n = len(res)\n",
        "FinalTraces = [0] * n\n",
        "FinalDeconvs = [0] * n\n",
        "for m in range(n):\n",
        "    h = res[m]\n",
        "    FinalTraces[m] = RawTraces[h]\n",
        "    FinalDeconvs[m] = DeconvTraces[h]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJEANAsRUhP7"
      },
      "source": [
        "# Plot again neurons without bad traces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgtqGGkzUmIg"
      },
      "source": [
        "\n",
        "neuronsToPlot = len(FinalTraces)\n",
        "plt.subplot(2,2,1); plt.figure; plt.title('Final Raw traces')\n",
        "plot_gain = 10\n",
        "maxFinalTraces = np.amax(FinalTraces)\n",
        "if numNeurons >= neuronsToPlot:\n",
        "  for i in range(neuronsToPlot):\n",
        "    if i == 0:\n",
        "      plt.plot(FinalTraces[i])\n",
        "    else:\n",
        "      trace = FinalTraces[i] + maxFinalTraces*i/plot_gain\n",
        "      plt.plot(trace)\n",
        "else:\n",
        "  for i in range(numNeurons):\n",
        "    if i == 0:\n",
        "      plt.plot(FinalTraces[i])\n",
        "    else:\n",
        "      trace = FinalTraces[i] + maxFinalTraces*i/plot_gain\n",
        "      plt.plot(trace)\n",
        "\n",
        "plt.subplot(2,2,2); plt.figure; plt.title('Final Deconvolved traces')\n",
        "plot_gain = 10 # To change the value gain of traces\n",
        "if numNeurons >= neuronsToPlot:\n",
        "  for i in range(neuronsToPlot):\n",
        "    if i == 0:\n",
        "      plt.plot(FinalDeconvs[i])\n",
        "    else:\n",
        "      trace = FinalDeconvs[i] + maxFinalTraces*i/plot_gain\n",
        "      plt.plot(trace)\n",
        "else:\n",
        "  for i in range(numNeurons):\n",
        "    if i == 0:\n",
        "      plt.plot(FinalDeconvs[i])\n",
        "    else:\n",
        "      trace = FinalDeconvs[i] + maxFinalTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "        \n",
        "        \n",
        "# Save summary figure\n",
        "plt.savefig(path_to_results + '/' + 'finaltraces.svg', edgecolor='w', format='svg', transparent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BAPq2Hw1L6O"
      },
      "source": [
        "# Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgrjN8PD1RCT"
      },
      "source": [
        "from scipy.io import savemat\n",
        "save_mat = True\n",
        "if save_mat:  \n",
        "    results_dict = {\n",
        "                'dirName': path_to_analyze,\n",
        "                'numFiles': len(msFileList),\n",
        "                'framesNum': len(RawTraces[1]),\n",
        "                'maxFramesPerFile': 1000,\n",
        "                'height': dims[0],\n",
        "                'width': dims[1],\n",
        "                'Experiment': experimentName,\n",
        "                'camNumber': 0,\n",
        "                'analysis_time': analysis_time,\n",
        "                'ds': spatial_downsampling,\n",
        "                'shifts': mc.shifts_rig,\n",
        "                'meanFrame': [], #TO DO\n",
        "                'Centroids': [], #TO DO\n",
        "                'CorrProj': cn_filter,\n",
        "                'PeakToNoiseProj': pnr,\n",
        "                'FiltTraces': FinalTraces,\n",
        "                'Decoaccepted': FinalDeconvs,\n",
        "                'RawTraces': RawTraces.conj().transpose(), #swap time x neurons dimensions\n",
        "                'SFP': SFP,\n",
        "                'numNeurons': SFP_dims[2],\n",
        "                'DeconvTraces': DeconvTraces\n",
        "                }\n",
        "\n",
        "    SFPperm = np.transpose(SFP,[2,0,1])\n",
        "    sio.savemat(path_to_results + '/SFP.mat', {'SFP': SFPperm})\n",
        "    sio.savemat(path_to_results + '/ms.mat', {'ms': results_dict})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npKbPWOr1aV7"
      },
      "source": [
        "if analyze_behavior:\n",
        "  print('Folytatjuk')\n",
        "else:\n",
        "  # Stop counter and register analysis time\n",
        "  analysis_end = time.time()\n",
        "  analysis_duration = analysis_end - analysis_start\n",
        "  print('Done analyzing. This took a total ' + str(analysis_duration) + ' s')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}